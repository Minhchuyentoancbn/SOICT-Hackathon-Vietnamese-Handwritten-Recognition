{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_LIST = [\n",
    "    'model1', 'model2', 'model3', 'model4', 'model5', \n",
    "    'model6', 'model7', 'model8', 'model9', 'model10',  \n",
    "    'model11', 'model12', 'model13', 'model14', 'model15', \n",
    "    'model16', 'model17', 'model19', 'model20', 'model21', \n",
    "    'model22', 'model23', 'model24', 'model25', 'model26', \n",
    "    'model27', 'model28', 'model29', 'model30', 'model31', \n",
    "    'model32', 'model34', 'model35', 'model36',\n",
    "    'model2_new', 'model3_new', 'model4_new', 'model5_new', 'model6_new', \n",
    "    'model7_new',  'model9_new', 'model10_new', 'model15_new', 'model17_new',\n",
    "    'model18_new', 'model19_new', 'model20_new',\n",
    "    'model3_tone', 'model4_tone', 'model5_tone', 'model7_tone', 'model6_tone',\n",
    "    'model9_tone', 'model10_tone', 'model20_tone',\n",
    "    'model19_new_tone', 'model30_tone', 'model33_tone', 'model34_tone', 'model35_tone',\n",
    "    'model1_synth',  'model2_synth', 'model3_synth', 'model4_synth', \n",
    "    'model5_synth', 'model6_synth', 'model7_synth', 'model8_synth' ,'model9_synth', \n",
    "    'model10_synth', 'model26_synth', 'model28_synth', 'model30_synth', 'model34_synth',\n",
    "    'model35_synth', 'model36_synth',\n",
    "    'model4_synth_new', 'model5_synth_new', 'model10_synth_new', 'model15_synth_new', 'model19_synth_new',\n",
    "    'model20_synth_new',\n",
    "    'model5_synth_tone', 'model19_synth_tone', 'model15_synth_tone',\n",
    "    'model4_synth_new_tone', 'model15_synth_new_tone', 'model19_synth_new_tone',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\anacoda3\\envs\\prompt\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from ensemble import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model_frame = get_model_frame(MODELS_LIST)\n",
    "model_dict = {model: i for i, model in enumerate(MODELS_LIST)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Character-based Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vote_cer_character(verbose=False, initial_baseline=None, max_len=-1):\n",
    "    if initial_baseline is None:\n",
    "        initial_baseline = []\n",
    "    candidates = [model for model in MODELS_LIST if model not in initial_baseline]\n",
    "\n",
    "    # Initial baseline\n",
    "    best_cer_test = 1.0\n",
    "    winning_candidates = None\n",
    "\n",
    "    print('Start hill climbing...')\n",
    "    # Hill climbing\n",
    "    while candidates:\n",
    "        best_candidate = None\n",
    "        best_cer = 1.0\n",
    "        for candidate in candidates:\n",
    "            cer, _ = compute_vote_char_cer(val_model_frame, initial_baseline + [candidate], mode='soft')\n",
    "            if cer < best_cer:\n",
    "                best_cer = cer\n",
    "                best_candidate = candidate\n",
    "\n",
    "        if best_cer < best_cer_test:\n",
    "            best_cer_test = best_cer\n",
    "            winning_candidates = initial_baseline + [best_candidate]\n",
    "        \n",
    "        initial_baseline.append(best_candidate)\n",
    "        candidates.remove(best_candidate)\n",
    "        if verbose:\n",
    "            print('-' * 50)\n",
    "            print(f'Add {best_candidate} to baseline')\n",
    "            print(f'CER Valid: {best_cer}')\n",
    "\n",
    "        if len(initial_baseline) == max_len:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Best CER: {best_cer_test}')\n",
    "        print(f'Winning candidates: {winning_candidates}')\n",
    "\n",
    "    return best_cer_test, winning_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cer, winning_candidates = compute_vote_cer_character(verbose=True, initial_baseline=['model3_tone', ])\n",
    "print(len(winning_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033041634"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_winning_candidates = [\n",
    "    'model3_tone', 'model2_new', 'model35', 'model2', 'model5_synth', 'model15_synth_new', 'model30', 'model35_tone', 'model20', 'model13', \n",
    "    'model17', 'model31', 'model9', 'model29', 'model2_synth', 'model15_new', 'model26_synth', 'model18_new', 'model30_tone', 'model33_tone', \n",
    "    'model34', 'model19', 'model30_synth', 'model14', 'model5_synth_tone', 'model19_synth_new_tone', 'model8_synth', 'model35_synth', 'model27', 'model34_tone', \n",
    "    'model5_new', 'model15_synth_tone', 'model1', 'model5_tone', 'model20_tone', 'model3_synth', 'model15', 'model6_new', 'model1_synth', 'model19_synth_new'\n",
    "]  # 0.0330 # 0.0333\n",
    "cer_char, char_based_pred = compute_vote_char_cer(val_model_frame, char_winning_candidates, mode='soft')\n",
    "cer_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Word-based Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary length: 10130\n"
     ]
    }
   ],
   "source": [
    "# Prepare dictionary\n",
    "labels = pd.read_csv(LABEL_FILE, header=None, na_filter=False, encoding='utf-8', sep='\\t')\n",
    "train_inds = pickle.load(open('train_inds.pkl', 'rb'))\n",
    "labels = labels.iloc[train_inds]\n",
    "labels.columns = ['id', 'label']\n",
    "vocab = labels['label'].str.lower().unique()\n",
    "vocab = pd.Series([delete_diacritic(label) for label in vocab]).unique()\n",
    "vocab_dict = {word: 1 for word in vocab}\n",
    "\n",
    "# Prepare validation mask\n",
    "val_model_frame = get_model_frame(MODELS_LIST)\n",
    "preds = np.array([val_model_frame[model]['pred'] for model in MODELS_LIST]).T\n",
    "val_mask = np.zeros_like(preds)\n",
    "for i in range(preds.shape[0]):\n",
    "    for j in range(preds.shape[1]):\n",
    "        val_mask[i, j] = vocab_dict.get(delete_diacritic(preds[i, j].lower()), 0) * 1.25\n",
    "        if preds[i, j] == char_based_pred[i]:\n",
    "            val_mask[i, j] += 0.25\n",
    "\n",
    "\n",
    "print(f\"Dictionary length: {len(vocab_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vote_cer_mask(verbose=False, initial_baseline=None, max_len=-1):\n",
    "    if initial_baseline is None:\n",
    "        initial_baseline = []\n",
    "    candidates = [model for model in MODELS_LIST if model not in initial_baseline]\n",
    "\n",
    "    # Initial baseline\n",
    "    best_cer_test = 1.0\n",
    "    winning_candidates = None\n",
    "    candidate_len = 0\n",
    "\n",
    "    print('Start hill climbing...')\n",
    "    # Hill climbing\n",
    "    while candidates:\n",
    "        best_candidate = None\n",
    "        best_cer = 1.0\n",
    "        for candidate in candidates:\n",
    "            mask = val_mask[:, [model_dict[model] for model in initial_baseline + [candidate]]]\n",
    "            cer, _ = compute_vote_cer(val_model_frame, initial_baseline + [candidate], mask=mask)\n",
    "            if cer < best_cer:\n",
    "                best_cer = cer\n",
    "                best_candidate = candidate\n",
    "\n",
    "        if best_cer < best_cer_test:\n",
    "            best_cer_test = best_cer\n",
    "            winning_candidates = initial_baseline + [best_candidate]\n",
    "        \n",
    "        # if best_cer != previous_cer:\n",
    "        initial_baseline.append(best_candidate)\n",
    "        candidates.remove(best_candidate)\n",
    "        previous_cer = best_cer\n",
    "        if verbose:\n",
    "            print('-' * 50)\n",
    "            print(f'Add {best_candidate} to baseline')\n",
    "            print(f'CER Valid: {best_cer}')\n",
    "\n",
    "        candidate_len += 1\n",
    "        if candidate_len == max_len:\n",
    "            break\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Best CER: {best_cer_test}')\n",
    "        print(f'Winning candidates: {winning_candidates}')\n",
    "\n",
    "    return best_cer_test, winning_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start hill climbing...\n",
      "--------------------------------------------------\n",
      "Add model3_tone to baseline\n",
      "CER Valid: 0.0353438908682026\n",
      "--------------------------------------------------\n",
      "Add model35_tone to baseline\n",
      "CER Valid: 0.03296706341056511\n",
      "--------------------------------------------------\n",
      "Add model30 to baseline\n",
      "CER Valid: 0.03199918867587441\n",
      "--------------------------------------------------\n",
      "Add model15_synth_new to baseline\n",
      "CER Valid: 0.03163651431299219\n",
      "--------------------------------------------------\n",
      "Add model10_synth to baseline\n",
      "CER Valid: 0.03138054189055857\n",
      "--------------------------------------------------\n",
      "Add model32 to baseline\n",
      "CER Valid: 0.031237323993083203\n",
      "--------------------------------------------------\n",
      "Add model8_synth to baseline\n",
      "CER Valid: 0.03108796970109747\n",
      "--------------------------------------------------\n",
      "Add model5_synth_new to baseline\n",
      "CER Valid: 0.03103409764667352\n",
      "--------------------------------------------------\n",
      "Add model5 to baseline\n",
      "CER Valid: 0.03097517508373718\n",
      "--------------------------------------------------\n",
      "Add model35_synth to baseline\n",
      "CER Valid: 0.030859272465711893\n",
      "--------------------------------------------------\n",
      "Add model5_synth to baseline\n",
      "CER Valid: 0.030808770783213653\n",
      "--------------------------------------------------\n",
      "Add model33_tone to baseline\n",
      "CER Valid: 0.03076908824288604\n",
      "--------------------------------------------------\n",
      "Add model18_new to baseline\n",
      "CER Valid: 0.03073705798316604\n",
      "--------------------------------------------------\n",
      "Add model31 to baseline\n",
      "CER Valid: 0.030706754953164044\n",
      "--------------------------------------------------\n",
      "Add model3_new to baseline\n",
      "CER Valid: 0.03068991993733247\n",
      "--------------------------------------------------\n",
      "Add model10 to baseline\n",
      "CER Valid: 0.03067638455580099\n",
      "--------------------------------------------------\n",
      "Add model10_synth_new to baseline\n",
      "CER Valid: 0.030615778495796997\n",
      "--------------------------------------------------\n",
      "Add model4_synth_new to baseline\n",
      "CER Valid: 0.030587476599652358\n",
      "--------------------------------------------------\n",
      "Add model4_synth to baseline\n",
      "CER Valid: 0.03055646891306988\n",
      "--------------------------------------------------\n",
      "Add model17_new to baseline\n",
      "CER Valid: 0.03049049559970817\n",
      "--------------------------------------------------\n",
      "Add model7 to baseline\n",
      "CER Valid: 0.03035985439743297\n",
      "--------------------------------------------------\n",
      "Add model35 to baseline\n",
      "CER Valid: 0.030246819282104268\n",
      "--------------------------------------------------\n",
      "Add model2 to baseline\n",
      "CER Valid: 0.030246815914097457\n",
      "--------------------------------------------------\n",
      "Add model20 to baseline\n",
      "CER Valid: 0.030246815914097457\n",
      "--------------------------------------------------\n",
      "Add model2_synth to baseline\n",
      "CER Valid: 0.030246815914097457\n",
      "Best CER: 0.030246815914097457\n",
      "Winning candidates: ['model19_new', 'model3_tone', 'model35_tone', 'model30', 'model15_synth_new', 'model10_synth', 'model32', 'model8_synth', 'model5_synth_new', 'model5', 'model35_synth', 'model5_synth', 'model33_tone', 'model18_new', 'model31', 'model3_new', 'model10', 'model10_synth_new', 'model4_synth_new', 'model4_synth', 'model17_new', 'model7', 'model35', 'model2']\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "best_cer, winning_candidates = compute_vote_cer_mask(verbose=True, initial_baseline=['model19_new', ], max_len=25)\n",
    "print(len(winning_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_cer_model = 1.0\n",
    "\n",
    "for model in MODELS_LIST:\n",
    "    best_cer, winning_candidates = compute_vote_cer_mask(verbose=False, initial_baseline=[model], max_len=20)\n",
    "    print(f'{model}: {best_cer}')\n",
    "    print('-' * 50)\n",
    "    if best_cer < best_cer_model:\n",
    "        best_cer_model = best_cer\n",
    "        best_model = model\n",
    "\n",
    "print(f'Best model: {best_model}')\n",
    "print(f'Best CER: {best_cer_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word CER: 0.030246815914097457\n"
     ]
    }
   ],
   "source": [
    "word_winning_candidates = [\n",
    "    'model19_new', 'model3_tone', 'model35_tone', 'model30', 'model15_synth_new', 'model10_synth', 'model32', 'model8_synth', \n",
    "    'model5_synth_new', 'model5', 'model35_synth', 'model5_synth', 'model33_tone', 'model18_new', 'model31', 'model3_new', \n",
    "    'model10', 'model10_synth_new', 'model4_synth_new', 'model4_synth', 'model17_new', 'model7', 'model35', 'model2'\n",
    "]\n",
    "mask = val_mask[:, [model_dict[model] for model in word_winning_candidates]]\n",
    "_, word_based_pred = compute_vote_cer(val_model_frame, word_winning_candidates, mask=mask)\n",
    "print(f\"Word CER: {_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word CER: 0.03262558852243183\n"
     ]
    }
   ],
   "source": [
    "word_winning_candidates = [\n",
    "    'model19_new', 'model3_tone', 'model35_tone', 'model30', 'model15_synth_new', 'model10_synth', 'model32', 'model8_synth', \n",
    "    'model5_synth_new', 'model5', 'model35_synth', 'model5_synth', 'model33_tone', 'model18_new', 'model31', 'model3_new', \n",
    "    'model10', 'model10_synth_new', 'model4_synth_new', 'model4_synth', 'model17_new', 'model7', 'model35', 'model2'\n",
    "]\n",
    "alpha = 1.25\n",
    "beta = 0.25\n",
    "mask = (alpha * word_mask + beta * char_mask)[:, [model_dict[model] for model in word_winning_candidates]]\n",
    "_, word_based_pred = compute_vote_cer(val_model_frame, word_winning_candidates, mask=mask)\n",
    "print(f\"Word CER: {_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "real = val_model_frame['model3_tone']['real']\n",
    "word_conf = np.array([val_model_frame[model]['confidence'] for model in word_winning_candidates]).T\n",
    "cer_word = np.array([val_model_frame[model]['cer'] for model in word_winning_candidates]).T\n",
    "score = word_conf + mask\n",
    "idx = np.argmax(score, axis=1)\n",
    "win_conf = word_conf[np.arange(len(word_conf)), idx]\n",
    "win_cer = cer_word[np.arange(len(cer_word)), idx]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'real': real,\n",
    "    'pred': word_based_pred,\n",
    "    'pred_char': char_based_pred,\n",
    "    'conf': win_conf,\n",
    "    'cer': win_cer,\n",
    "}).to_csv('ensemble/ensemble_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array([val_model_frame[model]['pred'] for model in word_winning_candidates]).T\n",
    "semantic_mask = np.zeros_like(preds)\n",
    "char_mask = np.zeros_like(preds)\n",
    "for i in range(preds.shape[0]):\n",
    "    for j in range(preds.shape[1]):\n",
    "        semantic_mask[i, j] = vocab_dict.get(delete_diacritic(preds[i, j].lower()), 0)\n",
    "        if preds[i, j] == char_based_pred[i]:\n",
    "            char_mask[i, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word CER: 0.030246815914097457\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.25\n",
    "beta = 0.25\n",
    "mask = alpha * semantic_mask + beta * char_mask\n",
    "cer_word, _ = compute_vote_cer(val_model_frame, word_winning_candidates, mask=mask)\n",
    "print(f\"Word CER: {cer_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.0, 2.0)\n",
    "    beta = trial.suggest_float('beta', 0.0, 2.0)\n",
    "    mask = (alpha * word_mask + beta * char_mask)[:, [model_dict[model] for model in word_winning_candidates]]\n",
    "    cer_word, _ = compute_vote_cer(val_model_frame, word_winning_candidates, mask=mask)\n",
    "    return cer_word\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=1000, n_jobs=-1)\n",
    "\n",
    "print(study.best_params) # 1.25 0.25\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_based_pred_full = make_final_char_prediction(add_full_to_lst(char_winning_candidates))\n",
    "pred = make_final_prediction(add_full_to_lst(word_winning_candidates), char_based_pred_full, alpha=1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for name in os.listdir('scripts/'):\n",
    "    if name.endswith('sh'):\n",
    "        with open(f'scripts/{name}', 'rb') as f:\n",
    "            command = f.read()\n",
    "        command = command.replace(b'!python', b'python3')\n",
    "        command = command.replace(b'\\r', bytes())\n",
    "        with open(f'scripts/{name}', 'wb') as f:\n",
    "            f.write(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model3_tone                   : 0.04175651146230674\n",
      "model19_synth_new             : 0.0418946353970754\n",
      "model5_new                    : 0.04213130448352207\n",
      "model5_tone                   : 0.042230304224473054\n",
      "model5_synth                  : 0.04314237113853898\n",
      "model35                       : 0.04334463688761297\n",
      "model3_new                    : 0.04344734224481414\n",
      "model5_synth_tone             : 0.043514215066426935\n",
      "model35_tone                  : 0.04372031508220567\n",
      "model19_synth_tone            : 0.04372323414818807\n",
      "model34_tone                  : 0.04383825131287478\n",
      "model19_new                   : 0.04389485601448651\n",
      "model33_tone                  : 0.04398200347041241\n",
      "model5                        : 0.04411927272727273\n",
      "model19                       : 0.04419002690775828\n",
      "model19_synth_new_tone        : 0.04421850069303705\n",
      "model34                       : 0.04431851710860778\n",
      "model7_tone                   : 0.0443748704306405\n",
      "model15_synth_new             : 0.04440697860311378\n",
      "model15                       : 0.04442243394752343\n",
      "model3_synth                  : 0.04446028472422951\n",
      "model4_synth                  : 0.04453258784581916\n",
      "model4_tone                   : 0.04465127694561626\n",
      "model7_new                    : 0.04472966181810456\n",
      "model17_new                   : 0.044766238041297354\n",
      "model5_synth_new              : 0.04477680857359159\n",
      "model6_synth                  : 0.04479738338728144\n",
      "model17                       : 0.044849489246956024\n",
      "model9_synth                  : 0.044892894769407284\n",
      "model7                        : 0.04491879797979798\n",
      "model19_new_tone              : 0.04493045343443601\n",
      "model4                        : 0.0449740808080808\n",
      "model7_synth                  : 0.04510750957360171\n",
      "model9_new                    : 0.045273824745055403\n",
      "model3                        : 0.04529646464646464\n",
      "model13                       : 0.045380585536059705\n",
      "model15_new                   : 0.045425684369272655\n",
      "model9                        : 0.04546764646464646\n",
      "model16                       : 0.045533627749543\n",
      "model35_synth                 : 0.04556507612042355\n",
      "model4_new                    : 0.04562548878668535\n",
      "model34_synth                 : 0.04571076209647487\n",
      "model20_new                   : 0.04571617697525506\n",
      "model20_tone                  : 0.04599408342154941\n",
      "model8_synth                  : 0.04605490449101034\n",
      "model8                        : 0.04622663636363636\n",
      "model4_synth_new_tone         : 0.0463810385071268\n",
      "model6                        : 0.04649147474747474\n",
      "model15_synth_tone            : 0.04659530124128467\n",
      "model15_synth_new_tone        : 0.04664864772422747\n",
      "model29                       : 0.04694778490999733\n",
      "model20_synth_new             : 0.04698962940787426\n",
      "model20                       : 0.04715510057530018\n",
      "model6_new                    : 0.047227372901156695\n",
      "model10_tone                  : 0.04735520409363689\n",
      "model27                       : 0.04738331624880584\n",
      "model10_synth                 : 0.047444234304506366\n",
      "model14                       : 0.047614567914996485\n",
      "model10                       : 0.047674969696969695\n",
      "model9_tone                   : 0.0477456484035109\n",
      "model36                       : 0.047797057967294346\n",
      "model10_new                   : 0.0479953307982045\n",
      "model12                       : 0.0480937125217734\n",
      "model32                       : 0.04810502414751534\n",
      "model30                       : 0.04818223619099819\n",
      "model2_new                    : 0.04820798320676943\n",
      "model4_synth_new              : 0.04829682336913215\n",
      "model23                       : 0.048568782886922963\n",
      "model11                       : 0.04892029224020062\n",
      "model24                       : 0.04938756877198966\n",
      "model2_synth                  : 0.04955162640924406\n",
      "model28                       : 0.04992676499741848\n",
      "model31                       : 0.050074066916348955\n",
      "model1_synth                  : 0.050311344250886125\n",
      "model28_synth                 : 0.05037075759410256\n",
      "model22                       : 0.05037914958716643\n",
      "model18_new                   : 0.050387536570279286\n",
      "model36_synth                 : 0.05042022331043927\n",
      "model2                        : 0.05049661616161616\n",
      "model30_tone                  : 0.05065116293653093\n",
      "model21                       : 0.050711329217360476\n",
      "model30_synth                 : 0.0510510453393664\n",
      "model6_tone                   : 0.05123013786821052\n",
      "model10_synth_new             : 0.051475194446516756\n",
      "model26_synth                 : 0.05207406667597366\n",
      "model1                        : 0.05245169696969697\n",
      "model25                       : 0.054706845525087734\n",
      "model26                       : 0.05539926199900984\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "val_model_frame = val_model_frame = get_model_frame(MODELS_LIST)\n",
    "cer_val = np.array([np.mean(val_model_frame[model]['cer']) for model in MODELS_LIST]).T\n",
    "\n",
    "# Sort by CER\n",
    "sorted_models = np.argsort(cer_val)\n",
    "for model in sorted_models:\n",
    "    print(f'{MODELS_LIST[model]:<30}: {cer_val[model]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lst = add_full_to_lst(list(set(word_winning_candidates + char_winning_candidates)))\n",
    "scripts = \"\"\n",
    "for i in range(len(final_lst)):\n",
    "    scripts += f\"bash scripts/{final_lst[i]}.sh\"\n",
    "    if i != len(final_lst) - 1:\n",
    "        scripts += \" &&\\n\"\n",
    "\n",
    "with open('scripts/train_all.sh', 'w') as f:\n",
    "    f.write(scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"trang\"\n",
    "vocab_dict[delete_diacritic(word.lower())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26564625"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torchmetrics.text import CharErrorRate\n",
    "import numpy as np\n",
    "\n",
    "cer = CharErrorRate()\n",
    "pred = pd.read_csv('ensemble/prediction.txt', header=None, na_filter=False, sep='\\t', index_col=0)\n",
    "\n",
    "gt = pd.read_csv('ensemble/second.txt', header=None, na_filter=False, sep='\\t', index_col=0)\n",
    "cer_lst = []\n",
    "for img in gt.index:\n",
    "    cer_lst.append(cer(pred.loc[img, 1], gt.loc[img, 1]))\n",
    "\n",
    "np.mean(cer_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29523808"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strongest = pd.read_csv('ensemble/private_test/model3_tone_full.csv', na_filter=False, index_col=0)\n",
    "cer_lst = []\n",
    "for img in gt.index:\n",
    "    cer_lst.append(cer(strongest.loc[img, 'pred'], gt.loc[img, 1]))\n",
    "np.mean(cer_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>private_test_1.jpg</th>\n",
       "      <td>0.644619</td>\n",
       "      <td>chết</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private_test_2.jpg</th>\n",
       "      <td>0.662872</td>\n",
       "      <td>lao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private_test_3.jpg</th>\n",
       "      <td>0.522751</td>\n",
       "      <td>trong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private_test_4.jpg</th>\n",
       "      <td>0.558205</td>\n",
       "      <td>dung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>private_test_5.jpg</th>\n",
       "      <td>0.180840</td>\n",
       "      <td>bh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    confidence   pred\n",
       "img_name                             \n",
       "private_test_1.jpg    0.644619   chết\n",
       "private_test_2.jpg    0.662872    lao\n",
       "private_test_3.jpg    0.522751  trong\n",
       "private_test_4.jpg    0.558205   dung\n",
       "private_test_5.jpg    0.180840     bh"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strongest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pred_hog = pd.read_csv('ensemble/prediction2.csv', na_filter=False)\n",
    "pred_no_hog = pd.read_csv('ensemble/prediction.csv', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = np.where(pred_hog['confidence'] > pred_no_hog['confidence'], pred_hog['pred'], pred_no_hog['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'img_name': pred_hog['img_name'], 'pred': final_pred})\n",
    "df.to_csv('ensemble/final_prediction.txt', index=False, header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strongest = pd.read_csv('ensemble/model3_tone_full.csv', na_filter=False)\n",
    "df = pd.DataFrame({'img_name': strongest['img_name'], 'pred': strongest['pred']})\n",
    "df.to_csv('ensemble/final_prediction.txt', index=False, header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
